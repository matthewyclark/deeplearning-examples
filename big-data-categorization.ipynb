{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Simple Categorization Example*\n",
    "\n",
    "This example creates a neural network that categorizes an integer as divisible by a given factor, e.g. 7.  Choosing higher numbers will result in a more sparse categorization, and allow experimenting with unbalanced data set categorizations.\n",
    "\n",
    "it generates a list of random 16 bit integers, and expresses them as a list of bits for the neural network,\n",
    "it also generates a list of 1 or 0 if the number is divisible by the factor\n",
    "\n",
    "The resulting model can \"predict\" if a number is divisible by the factor.\n",
    "\n",
    "\n",
    "*Required python software packages (install with pip):*\n",
    "\n",
    "    numpy\n",
    "    tensorflow\n",
    "    matplotlib\n",
    "\n",
    "*Conclusions*\n",
    "\n",
    "One can train a model to categorize integers. Obviously this can be done more easily.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random integers each as a list of bits:\n",
      "x [[0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1]\n",
      " [1 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1]\n",
      " [0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1]\n",
      " [1 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1]\n",
      " [0 0 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
      " [1 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 0]\n",
      " [0 0 1 1 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1]\n",
      " [1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1]]\n",
      "\n",
      "this above is the list of random numbers expressed as bits\n",
      "\n",
      "\n",
      "array of 1,0 if the number is divisible by 4\n",
      "y [1 0 1 1 0 1 0 0 1 1]\n",
      "\n",
      "in this array 1 = divisible by 4,  0 = not evenly divisible\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# numpy is an essential library of numeric methods for python. It is also optimized\n",
    "# for high performance.\n",
    "# https://numpy.org/\n",
    "\n",
    "\n",
    "nrows = 10000  # number of rows of data to generate\n",
    "numEpochs = 1000 # maximum number of steps to run\n",
    "factor = 4  # find integers that are evenly divisible by this - try different values!\n",
    "            # you will find that powers of 2 (single bits) give the lowest error, other\n",
    "            # values will require longer training periods, have higher errors, and may require\n",
    "            # larger neural networks.\n",
    "\n",
    "\n",
    "maxbits = 20 # size of integer to generate, 2**maxbits\n",
    "\n",
    "#\n",
    "# create a data set for y = mx + b, linearly related variables\n",
    "# returns a tuple (x,y) of 'nrows' of correlated data\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
    "def create_data():\n",
    "    \n",
    "    # use the numpy library to create a random list\n",
    "    # of numbers beteen 0 and 1.  np.random.uniform supplies this.\n",
    "    # https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
    "    \n",
    "    number = np.random.randint(low=0, high=2**maxbits, size=nrows)\n",
    "    \n",
    "    # make an indicator category 0, 1 to indicate whether the number is evenly\n",
    "    # divisible by 'factor'.  This is a very simple 'yes/no' categorization that\n",
    "    # also represent toxic/nontoxic or other variables.    \n",
    "    \n",
    "    #  this is a \"pythonic\" way to compute the list.\n",
    "    #\n",
    "    #  val = [ f(x) for x in <list> ] results in a list 'val', with a size \n",
    "    #  the same as <list>, and each entry has the value of the function f(x) for the\n",
    "    #  values x in < list>\n",
    "    # example:\n",
    "    #  val = [ 2*x for x in range(5)]\n",
    "    #  result in val = [0, 2, 4, 6, 8]\n",
    "\n",
    "    category = [num % factor & 1 for num in number]\n",
    "    \n",
    "    # create an array of 'maxbit' numbers corresponding to the bits in the integer\n",
    "    # converting the integer into a list of bits.\n",
    "    # Tensorflow will not otherwise look at bits in an integer, it would only\n",
    "    # look to see the magnitude of the number\n",
    "    bits = [[num >> k & 1 for k in range(maxbits - 1,-1,-1)] for num in number]\n",
    "    \n",
    "    # this \"pythonic\" computation of \"bits\" above is the equivalent of this loop:\n",
    "    #\n",
    "    # array to hold numbers as arrays of bits; this will be a list of lists.  \n",
    "    # in python list = 'array' in other languages\n",
    "    #bits     = []\n",
    "    #for i in range(nrows):\n",
    "        #entry = [number[i] >> k & 1 for k in range(maxbits - 1,-1,-1)]\n",
    "        #bits.append(entry)    \n",
    "    \n",
    "    # return x,y as a tuple of numpy arrays\n",
    "    return (np.array(bits), np.array(category))\n",
    "\n",
    "\n",
    "x,y = create_data()\n",
    "\n",
    "# print first 10 values to see the results\n",
    "print('\\nrandom integers each as a list of bits:')\n",
    "print('x', x[:10])  # use python list syntax for first 10\n",
    "print('\\nthis above is the list of random numbers expressed as bits\\n')\n",
    "print('\\narray of 1,0 if the number is divisible by', factor)\n",
    "print('y', y[:10])\n",
    "print('\\nin this array 1 = divisible by %d,  0 = not evenly divisible' % (factor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = int(1e6)  # number of rows of data to generate\n",
    "numEpochs = 1000 # maximum number of steps to run\n",
    "factor = 4  # find integers that are evenly divisible by this - try different values!\n",
    "            # you will find that powers of 2 (single bits) give the lowest error, other\n",
    "            # values will require longer training periods, have higher errors, and may require\n",
    "            # larger neural networks.\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "maxbits = 20 # size of integer to generate, 2**maxbits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "In big-data situations the data won't all fit in memory.  In that case we use a generator to\n",
    "feed the data to Tensorflow in batches.  The data could be read from files or other sources.\n",
    "\n",
    "In this example we generate a large number of random data, and create a linearly correlated data\n",
    "set.  This can generate an \"unlimited\" size data set.\n",
    "\"\"\"\n",
    "\n",
    "# implement a class of type 'keras.utils.Sequence'\n",
    "# https://keras.io/api/utils/python_utils/#sequence-class\n",
    "class category_generator(keras.utils.Sequence):\n",
    "    \n",
    "    # initialize with batch_size and nrows - total data size\n",
    "    # in a class all methods have the 'self' argument first.\n",
    "    def __init__(self, batch_size, nrows):\n",
    "        self.batch_size = batch_size # store batch_size in this class\n",
    "        self.nrows = nrows\n",
    "        self.batches = int(nrows/batch_size)\n",
    "     \n",
    "    # return number of batches this generator will produce\n",
    "    def __len__(self):\n",
    "        return self.batches\n",
    "    \n",
    "    \n",
    "    # this method is called for each batch. In this example we ignore the\n",
    "    # batch index, idx, because it is just random numbers. But in a real\n",
    "    # situation you would retrieve a specific batch of data\n",
    "    def __getitem__(self, idx):\n",
    "        # https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
    "        number = np.random.randint(low=0, high=2**maxbits, size=self.batch_size)\n",
    "        bits = [[num >> k & 1 for k in range(maxbits - 1,-1,-1)] for num in number]\n",
    "        category = [num % factor & 1 for num in number]\n",
    "        \n",
    "        return (np.array(bits), np.array(category))\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create the Neural Network model topology, which is one layer\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "def makeModel():\n",
    "\n",
    "    # these two lines clear out the model so you can re-run \n",
    "    # the notebook with different conditions\n",
    "    keras.backend.clear_session()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    # https://keras.io/api/models/sequential/#sequential-class\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # https://keras.io/api/layers/core_layers/input/\n",
    "    # it has to be the size of the list of bits for the integers.\n",
    "    model.add(keras.Input(shape=(maxbits,)))\n",
    "    \n",
    "    # define layers of neurons.  There are many options that \n",
    "    # could be used here but the default are used for this simple example\n",
    "    \n",
    "    # https://keras.io/api/layers/core_layers/dense/\n",
    "    # https://keras.io/api/layers/activations/#relu-function\n",
    "    # the activation function modifies the network coefficients\n",
    "    # https://keras.io/api/layers/normalization_layers/layer_normalization/\n",
    "    \n",
    "    # add more layers here to experiment with the neural network\n",
    "    \n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    #model.add(keras.layers.LayerNormalization()) # normalize coefficients to help stability\n",
    "    model.add(keras.layers.Dense(units=1,  activation='sigmoid', name='output_layer'))\n",
    "     \n",
    "    # keras metrics - these are built in and keras will compute them for you to measure\n",
    "    # the training.  They are not minimized during training; only the loss function(s)\n",
    "    # are minimized.  \n",
    "    tp = tf.keras.metrics.TruePositives()\n",
    "    tn = tf.keras.metrics.TrueNegatives()\n",
    "    fp = tf.keras.metrics.FalsePositives()\n",
    "    fn = tf.keras.metrics.FalseNegatives()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "    \n",
    "    # compile the network using default options.  The SGD optimizer\n",
    "    # is good for general purpose, but would probably benefit from a custom\n",
    "    # learning rate for this example\n",
    "    # https://keras.io/api/optimizers/sgd/\n",
    "    # \n",
    "    # see this for the loss function\n",
    "    # https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "    #\n",
    "    # the loss is function that will be minimized in the fitting process\n",
    "    # https://keras.io/api/models/model_training_apis/#compile-method\n",
    "    \n",
    "    model.compile(optimizer='RMSprop', loss='binary_crossentropy',metrics=[tp,tn,fp,fn,auc])\n",
    "    \n",
    "    #show the model structure and layer size\n",
    "    # the model has 2 trainable variables - enough for a perfect fit.\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "976/976 [==============================] - 17s 17ms/step - loss: 0.1124 - true_positives: 493639.0000 - true_negatives: 492222.0000 - false_positives: 7080.0000 - false_negatives: 6483.0000 - auc: 0.9994\n",
      "Epoch 2/1000\n",
      "976/976 [==============================] - 17s 18ms/step - loss: 3.4063e-07 - true_positives: 499538.0000 - true_negatives: 499886.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - auc: 1.0000\n",
      "Epoch 3/1000\n",
      "976/976 [==============================] - 17s 18ms/step - loss: 1.0132e-08 - true_positives: 499585.0000 - true_negatives: 499839.0000 - false_positives: 0.0000e+00 - false_negatives: 0.0000e+00 - auc: 1.0000\n",
      "num epochs 3\n",
      "tp 5023 tn 4977 fp   0 fn   0 auc 1.000 loss 0.000\n",
      "CPU times: user 1min 8s, sys: 3.04 s, total: 1min 11s\n",
      "Wall time: 54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Put the elements together to generate data, make the model, and perform the training\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# create the random data\n",
    "\n",
    "train_data = category_generator(batch_size, nrows)\n",
    "validate_data = category_generator(batch_size, 1000)\n",
    "\n",
    "# create the neural network\n",
    "model = makeModel()\n",
    "\n",
    "\n",
    "# this will monitor the error and stop if the delta is less than min_delta\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=1e-5,\n",
    "    patience=1,\n",
    ")\n",
    "\n",
    "# fit the model with 500 steps.  There is a way to stop on specified change\n",
    "# in error but this is a simple example.\n",
    "#\n",
    "# https://keras.io/api/models/model_training_apis/#fit-method\n",
    "history = model.fit(\n",
    "    x=train_data,    # dependent variable\n",
    "    validation_data=validate_data,    # validation data\n",
    "    epochs=numEpochs,  # try changing this to see how the error changes\n",
    "    verbose=1,    # change this from 0-5 to get more info as the training proceeds\n",
    "    callbacks=earlystop # this uses the 'earlystop' callback above to know when to stop\n",
    "    )\n",
    "\n",
    "print('num epochs', len(history.history['loss']))\n",
    "loss, tp, tn, fp, fn, auc = model.evaluate(x,y, verbose = 0)\n",
    "print('tp %3d tn %3d fp %3d fn %3d auc %4.3f loss %4.3f' % (tp, tn, fp, fn, auc, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.html\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00]\n",
      " [7.4651463e-10]\n",
      " [1.0000000e+00]\n",
      " ...\n",
      " [1.2890672e-09]\n",
      " [1.0000000e+00]\n",
      " [2.8907250e-09]]\n"
     ]
    }
   ],
   "source": [
    "# example of predicted output. it is a floating point number that\n",
    "# corresponds to the 'confidence' that the category is 1, or divisible.\n",
    "pred = model.predict(x)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy metrics\n",
      "\n",
      "true positive    504 false negative     0\n",
      "false positive     0 true negative    496\n",
      "\n",
      "auc 1.000\n",
      "positive predictive value 1.000\n",
      "negative predictive value 1.000\n",
      "F1 score 1.000\n"
     ]
    }
   ],
   "source": [
    "# create new data for a test set\n",
    "# this will generate a new data set not used for training\n",
    "x,y = category_generator(1000,1000).__getitem__(0)\n",
    "\n",
    "# compute metrics with model by predicting.\n",
    "loss, tp, tn, fp, fn, auc = model.evaluate(x,y, verbose = 0)\n",
    "print('accuracy metrics\\n')\n",
    "print('true positive  %5d false negative %5d\\nfalse positive %5d true negative  %5d\\n\\nauc %4.3f' % (tp, fn, fp, tn, auc))\n",
    "\n",
    "ppv = tp/(tp+fp+.01)\n",
    "npv  =  tn/(tn+fn+.01)\n",
    "F1  = 2*tp/(2*tp + fp + fn+.01)\n",
    "print('positive predictive value %3.3f\\nnegative predictive value %3.3f\\nF1 score %3.3f' %(ppv, npv, F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3249636 ,  0.0251838 , -0.14300272,  0.11157191,  0.09881493,\n",
       "        0.26942256,  0.32359555,  0.03650909,  0.14816871,  0.08018949,\n",
       "       -0.2649219 , -0.1323809 ,  0.35542455,  0.17975236, -0.00129553,\n",
       "        0.4309723 ,  0.01143879,  0.18294294,  0.15230031,  0.2820894 ,\n",
       "        0.2822877 ,  0.00130329, -0.02305873,  0.06828669, -0.03662499,\n",
       "        0.39454198,  0.31400296,  0.40683198, -0.03600561, -0.26267895,\n",
       "        0.12041561,  0.06198462], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the coefficients can be retrieved by layer\n",
    "model.get_weights()[0][0]\n",
    "# you can see which bits have the highest coefficients, however it is difficult to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "standard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
